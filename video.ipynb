{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[152, 182, 215],\n",
       "        [152, 182, 215],\n",
       "        [152, 182, 215],\n",
       "        ...,\n",
       "        [ 84,  81,  91],\n",
       "        [ 83,  80,  90],\n",
       "        [ 82,  79,  89]],\n",
       "\n",
       "       [[152, 182, 215],\n",
       "        [152, 182, 215],\n",
       "        [152, 182, 215],\n",
       "        ...,\n",
       "        [ 84,  81,  91],\n",
       "        [ 83,  80,  90],\n",
       "        [ 82,  79,  89]],\n",
       "\n",
       "       [[152, 182, 215],\n",
       "        [152, 182, 215],\n",
       "        [152, 182, 215],\n",
       "        ...,\n",
       "        [ 86,  82,  93],\n",
       "        [ 83,  80,  90],\n",
       "        [ 81,  77,  88]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[104, 119, 141],\n",
       "        [104, 119, 141],\n",
       "        [104, 119, 141],\n",
       "        ...,\n",
       "        [ 73,  76,  90],\n",
       "        [ 73,  76,  90],\n",
       "        [ 73,  76,  90]],\n",
       "\n",
       "       [[104, 119, 141],\n",
       "        [104, 119, 141],\n",
       "        [104, 119, 141],\n",
       "        ...,\n",
       "        [ 73,  76,  90],\n",
       "        [ 73,  76,  90],\n",
       "        [ 73,  76,  90]],\n",
       "\n",
       "       [[104, 119, 141],\n",
       "        [104, 119, 141],\n",
       "        [104, 119, 141],\n",
       "        ...,\n",
       "        [ 73,  76,  90],\n",
       "        [ 73,  76,  90],\n",
       "        [ 73,  76,  90]]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected classes and their counts:\n",
      "{'Direction-Sign': 2074, 'Order-Sign': 955, 'Street-Direction-Sign': 25, 'Warning-Sign': 333}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# load class names from data.yaml\n",
    "def load_class_names(yaml_path):\n",
    "    with open(yaml_path, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    return data['names']\n",
    "\n",
    "def generate_colors(num_colors):\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    return [tuple(np.random.randint(0, 255, size=3).tolist()) for _ in range(num_colors)]\n",
    "\n",
    "# Load class names\n",
    "data_yaml_path = '/Users/wailim0506/Desktop/yolov8Batch32/DataSet/dataset/data.yaml'\n",
    "class_names = load_class_names(data_yaml_path)\n",
    "\n",
    "colors = generate_colors(len(class_names))\n",
    "\n",
    "# Load trained YOLO model\n",
    "model = YOLO('/Users/wailim0506/Desktop/yolov8Batch32/trainedModel.pt')\n",
    "\n",
    "directory_path = '/Users/wailim0506/Desktop/yolov8Batch32/VideoForDemo' \n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "\n",
    "    video_path = f\"{directory_path}/{filename}\"\n",
    "\n",
    "    try: \n",
    "        # Path to input video and output video\n",
    "        input_video_path = video_path\n",
    "        output_video_path = f\"/Users/wailim0506/Desktop/yolov8Batch32/output_of_{filename}.mp4\"\n",
    "\n",
    "        # Open input video\n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "        # Get the width, height, and frame rate of the frames\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)  # Get the frame rate of the input video\n",
    "\n",
    "        # Check FPS is valid \n",
    "        if fps == 0:\n",
    "            print(\"Warning: FPS value is zero. Setting default FPS to 30.\")\n",
    "            fps = 30  # Set a default value for FPS if it's zero\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4 format\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        # count detected classes\n",
    "        class_count = {class_name: 0 for class_name in class_names}\n",
    "\n",
    "        # Calculate total frames \n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # Calculate the estimated time\n",
    "        estimated_time_seconds = total_frames / fps\n",
    "        estimated_time_minutes = estimated_time_seconds / 60  # Convert to minutes\n",
    "        #print(f\"Estimated time to process the entire video: {estimated_time_minutes:.2f} minutes\")\n",
    "\n",
    "        # Process frame\n",
    "        processed_frames = 0  # Initialize processed frames count\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Process frame\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # Exit the loop, no frames left\n",
    "\n",
    "            # object detection \n",
    "            results = model(frame) \n",
    "\n",
    "            # Draw bounding boxes and labels \n",
    "            boxes = results[0].boxes \n",
    "\n",
    "        \n",
    "            label_positions = []\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0] \n",
    "                cls_index = int(box.cls[0])  \n",
    "                confidence = box.conf[0]  \n",
    "\n",
    "                x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
    "\n",
    "                # Get the class name from the index\n",
    "                class_name = class_names[cls_index]\n",
    "                rectangle_color = colors[cls_index]  \n",
    "\n",
    "                # count for class\n",
    "                class_count[class_name] += 1\n",
    "\n",
    "                # Draw rectangle \n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), rectangle_color, thickness=6)\n",
    "\n",
    "                \n",
    "                font_scale = 1.5 \n",
    "                thickness = 5    \n",
    "\n",
    "                #class name + confidence score\n",
    "                text = f'{class_name} {confidence:.2f}'\n",
    "\n",
    "             \n",
    "                (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n",
    "\n",
    "                new_y_position = y1 - 5\n",
    "\n",
    "                for pos in label_positions:\n",
    "                    if abs(new_y_position - pos) < text_height + 10: \n",
    "                        new_y_position = y2 + text_height + 10  \n",
    "                        break\n",
    "                    \n",
    "            \n",
    "                background_color = rectangle_color  \n",
    "                cv2.rectangle(frame, (x1, new_y_position - text_height - 10), (x1 + text_width, new_y_position), background_color, cv2.FILLED)\n",
    "\n",
    "                \n",
    "                cv2.putText(frame, text,\n",
    "                            (x1, new_y_position), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            font_scale, (255, 255, 255), thickness)  \n",
    "\n",
    "                label_positions.append(new_y_position)\n",
    "\n",
    "            # Write the annotated frame to the output video file.\n",
    "            out.write(frame)\n",
    "\n",
    "            processed_frames += 1  \n",
    "\n",
    "            \n",
    "            clear_output(wait=True) \n",
    "            display(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) \n",
    "\n",
    "            \n",
    "            frame_time = 1 / fps \n",
    "            elapsed_time = time.time() - start_time  \n",
    "            sleep_time = max(0, frame_time - (elapsed_time % frame_time))  \n",
    "            time.sleep(sleep_time)  \n",
    "\n",
    "        \n",
    "        cap.release()\n",
    "        out.release()  # Save output video file.\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        print(\"Detected classes and their counts:\")\n",
    "        print(class_count)\n",
    "    except:\n",
    "        continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
